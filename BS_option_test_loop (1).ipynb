{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b809a9c-d529-42a6-a640-d477405c066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "   stock        IV     log_r   pos_log   neg_log  pos_periods  ttl_periods  \\\n",
      "0   AMLP  0.336921 -0.713607  0.871572 -1.585178           41           69   \n",
      "1   ARKF  0.551762  0.766860  2.004950 -1.238090           50           69   \n",
      "2   ARKG  0.515386 -0.711116  1.223940 -1.935056           31           69   \n",
      "3   ARKK  0.564946  0.063280  1.619397 -1.556117           40           69   \n",
      "4   ASHR  0.231697 -0.071377  0.739744 -0.811122           38           69   \n",
      "..   ...       ...       ...       ...       ...          ...          ...   \n",
      "87   XLY  0.395697  1.054844  1.721443 -0.666599           50           69   \n",
      "88   XME  0.415045 -0.201073  1.145333 -1.346406           42           69   \n",
      "89   XOP  0.466375 -1.099462  1.173151 -2.272613           36           69   \n",
      "90   XRT  0.503789  1.049120  1.957090 -0.907971           54           69   \n",
      "91  YINN  0.798830 -0.037906  2.497765 -2.535672           42           69   \n",
      "\n",
      "    avg_yield  opt_yield_perc    sharpe      winr  \n",
      "0   -0.010342        0.048342  0.549826  0.594203  \n",
      "1    0.011114        0.078662  1.619389  0.724638  \n",
      "2   -0.010306        0.073311  0.632509  0.449275  \n",
      "3    0.000917        0.080256  1.040665  0.579710  \n",
      "4   -0.001034        0.033561  0.912002  0.550725  \n",
      "..        ...             ...       ...       ...  \n",
      "87   0.015288        0.056192  2.582426  0.724638  \n",
      "88  -0.002914        0.059504  0.850659  0.608696  \n",
      "89  -0.015934        0.066271  0.516213  0.521739  \n",
      "90   0.015205        0.071649  2.155455  0.782609  \n",
      "91  -0.000549        0.113336  0.985051  0.608696  \n",
      "\n",
      "[92 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class BsOption:\n",
    "    def __init__(self, S, K, T, r, sigma, q=0):\n",
    "        self.S = S\n",
    "        self.K = K\n",
    "        self.T = T\n",
    "        self.r = r\n",
    "        self.sigma = sigma\n",
    "        self.q = q\n",
    "\n",
    "    @staticmethod\n",
    "    def N(x):\n",
    "        return norm.cdf(x)\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return {'S': self.S,\n",
    "                'K': self.K,\n",
    "                'T': self.T,\n",
    "                'r': self.r,\n",
    "                'q': self.q,\n",
    "                'sigma': self.sigma}\n",
    "\n",
    "    def d1(self):\n",
    "        return (np.log(self.S / self.K) + (self.r - self.q + self.sigma ** 2 / 2) * self.T) \\\n",
    "               / (self.sigma * np.sqrt(self.T))\n",
    "\n",
    "    def d2(self):\n",
    "        return self.d1() - self.sigma * np.sqrt(self.T)\n",
    "\n",
    "    def _call_value(self):\n",
    "        return self.S * np.exp(-self.q * self.T) * self.N(self.d1()) - \\\n",
    "               self.K * np.exp(-self.r * self.T) * self.N(self.d2())\n",
    "\n",
    "    def _put_value(self):\n",
    "        return self.K * np.exp(-self.r * self.T) * self.N(-self.d2()) - \\\n",
    "               self.S * np.exp(-self.q * self.T) * self.N(-self.d1())\n",
    "\n",
    "    def price(self):\n",
    "        # return self._call_value()\n",
    "        return self._call_value(), self._put_value()\n",
    "\n",
    "\n",
    "def GetData(stk, start_date, end_date):\n",
    "    df = yf.download(stk, start_date, end_date, interval='1d').dropna()\n",
    "    return (df)\n",
    "\n",
    "\n",
    "def AddTime(df):\n",
    "    df['start']=df.index\n",
    "    df['end']=df.index\n",
    "    df['dow'] = df.index.dayofweek\n",
    "    #df['moy']\n",
    "    df['woy'] = df.index.isocalendar().week + df.index.isocalendar().year * 100\n",
    "    df['moy']=df.index.strftime('%m-%Y')\n",
    "    return (df)\n",
    "\n",
    "def GroupW(df,div,type):\n",
    "    #df=df[df['dow']!=3]\n",
    "    #df=df[df['dow']!=2]\n",
    "    #df=df[df['dow']!=1]\n",
    "    #df=df[df['dow']!=0]\n",
    "    if type==\"week\":\n",
    "        df['woy']=(df.woy/div).apply(np.ceil)\n",
    "        df = df.groupby(['woy']).agg({'start':'first','end':'last','Open': 'first', 'Close': 'last'})\n",
    "        df['days']= (df['end'] - df['start']).dt.days+1\n",
    "        df=df.set_index('start')\n",
    "    #if type==\"month\":\n",
    "    #    df['moy'] = (df.moy/div).apply(np.ceil)\n",
    "    #    df = df.groupby(['moy']).agg({'Open': 'first', 'Close': 'last'})\n",
    "    return (df)\n",
    "\n",
    "def Outs(df,IV):\n",
    "    df['K'] = df.Open.round(0)\n",
    "    df['C1'] = BsOption(df.Open, df.K, df.days / 365, 0.03, IV).price()[0]\n",
    "    df['C2'] = BsOption(df.Close, df.K, 0 / 365, 0.03, IV).price()[0]\n",
    "    df['P1'] = BsOption(df.Open, df.K, df.days / 365, 0.03, IV).price()[1]\n",
    "    df['P2'] = BsOption(df.Close, df.K, 0 / 365, 0.03, IV).price()[1]\n",
    "    df['T1'] = df.C1 + df.P1\n",
    "    df['T2'] = df.C2 + df.P2\n",
    "    df['PL'] = df.T1 - df.T2\n",
    "    df['LogR'] = np.log((df.Open + df.PL) / df.Open)\n",
    "    df['OptionYield']=df.T1/df.K\n",
    "    return(df)\n",
    "\n",
    "df0=pd.read_csv('option_data_2022-08-19_2022-08-06.csv')\n",
    "#Inputs\n",
    "#intervals=[1,2,4,12,24,48]\n",
    "#stock=df0.symbol[0]\n",
    "#start_date='2020-01-13'\n",
    "#end_date='2020-12-24'\n",
    "\n",
    "#start_date='2021-01-11'\n",
    "#end_date='2021-12-24'\n",
    "\n",
    "#start_date='2022-01-03'\n",
    "#end_date='2022-06-25'\n",
    "\n",
    "start_date='2020-01-01'\n",
    "end_date='2022-08-06'\n",
    "\n",
    "#IV = (df0.atm_call_IV[0]+df0.atm_put_IV[0])/2\n",
    "div=2\n",
    "type=\"week\"\n",
    "arr=[]\n",
    "for i in range (0,len(df0.symbol)):\n",
    "    stock=df0.symbol[i]\n",
    "    IV = (df0.atm_call_IV[i]+df0.atm_put_IV[i])/2\n",
    "    df = GetData(stock, start_date, end_date)\n",
    "    df = AddTime(df)\n",
    "    df=GroupW(df,div,type)\n",
    "    df=Outs(df,IV)\n",
    "    log_r=np.sum(df.LogR)\n",
    "    pos_log=np.sum(df[df.LogR > 0].LogR)\n",
    "    neg_log=np.sum(df[df.LogR <= 0].LogR)\n",
    "    pos_periods=len(df[df.LogR > 0].LogR)\n",
    "    ttl_periods=(len(df.LogR))\n",
    "    avg_yield=np.average(df.LogR.dropna())\n",
    "    opt_yield=np.average(df.OptionYield)\n",
    "    arr.append([stock,IV,log_r,pos_log,neg_log,pos_periods,ttl_periods,avg_yield,opt_yield])\n",
    "    #print(df)\n",
    "    #filename=(stock+\", \"+start_date+\", \"+end_date+\", \"+str(div)+\".csv\")\n",
    "    #df.to_csv(filename)\n",
    "    #Sum Log Returns\n",
    "    #print(np.sum(df.LogR))\n",
    "    #Sum Positive Log\n",
    "    #print(np.sum(df[df.LogR > 0].LogR))\n",
    "    #Sum Negative Log\n",
    "    #print(np.sum(df[df.LogR <= 0].LogR))\n",
    "    #Count of Positive Periods\n",
    "    #print(len(df[df.LogR > 0].LogR))\n",
    "    #Total Count of Periods\n",
    "    #print(len(df.LogR))\n",
    "    #Average Option Yield\n",
    "    #print(np.average(df.OptionYield))\n",
    "    #print((np.sum(df[df.LogR > 0].LogR))/(-(np.sum(df[df.LogR <= 0].LogR))))\n",
    "    #Days/Period\n",
    "finaldf=pd.DataFrame(data=arr,columns=['stock','IV','log_r','pos_log','neg_log','pos_periods','ttl_periods','avg_yield','opt_yield_perc'])\n",
    "finaldf['sharpe']=abs(finaldf.pos_log/finaldf.neg_log)\n",
    "finaldf['winr']=finaldf.pos_periods/finaldf.ttl_periods\n",
    "finaldf.to_csv('big.csv')\n",
    "print(finaldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6baf21e-e359-40af-80be-da08ce1bbc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
